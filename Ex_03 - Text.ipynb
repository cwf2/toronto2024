{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cwf2/toronto2024/blob/main/Ex_03%20-%20Text.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving texts and counting words\n",
    "\n",
    "In this example, we'll retrieve the texts of speeches from a remote server and do a basic word count.\n",
    "\n",
    "## Scenario\n",
    "\n",
    "Let's say we want to know how many words Aphrodite speaks to each of her interlocutors. We can search the DICES database for the relevant speeches using the API. Then, to count the number of words, we'll have to retrieve the text of the speeches themselves. Since the DICES *Speech* objects include CTS URNS, we can request the passages from a remote server. \n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "### The DICES API\n",
    "\n",
    "First step is to instantiate a connection to the DICES api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab only:\n",
    "#   run the line below to install the DICES client\n",
    "\n",
    "!pip install --quiet git+https://github.com/cwf2/dices-client.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicesapi import DicesAPI\n",
    "api = DicesAPI(logfile='dices.log', logdetail=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to the digital library\n",
    "\n",
    "Text-retrieval and processing tools are moving to the module `text`. We retrieve the text from an online (or locally mirrored) digital library. By default, it's Perseus's [CTS endpoint](https://scaife-cts.perseus.org/api/cts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicesapi.text import CtsAPI\n",
    "cts = CtsAPI(dices_api=api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional modules\n",
    "\n",
    "Let's also import **pyplot**, for drawing a simple bar graph of the results, and Pandas for tabular results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the speeches\n",
    "\n",
    "### First, the speech metadata from DICES\n",
    "\n",
    "Using the API, we can search speeches using a set of key-value pairs. For now, JSON results from the API are paged, so if your search has a lot of results, you may have to wait for several pages to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = api.getSpeeches(spkr_name='Aphrodite', work_title='Iliad')\n",
    "\n",
    "print(f'Got {len(speeches)} speeches.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, the text of the speeches from Perseus\n",
    "\n",
    "This involves retrieving each passage from the CTS server, and extracting the plaintext of its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []\n",
    "\n",
    "# iterate over all speeches\n",
    "for i, s in enumerate(speeches):\n",
    "    print(f'\\r [{i+1}/{len(speeches)}]', end='')\n",
    "    \n",
    "    # retrieve the passage from the remote library\n",
    "    s.passage = cts.getPassage(s)\n",
    "    \n",
    "    if s.passage is None:\n",
    "        failed.append(s)\n",
    "        \n",
    "print(' done.')\n",
    "if len(failed) > 0:\n",
    "    print(f'Failed to download text for {len(failed)} speeches:')\n",
    "    for s in failed:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CLTK's NLP pipeline\n",
    "\n",
    "We run a stripped-down version of CLTK's default NLP pipeline, specific to the speech's language. By default, our wrapper method around the NLP pipeline also creates an index recording the locus of each token. For this example, I'm going to turn that feature off to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []\n",
    "\n",
    "# iterate over all speeches\n",
    "for s in speeches:\n",
    "    print(f'\\r [{i+1}/{len(speeches)}]', end='')\n",
    "\n",
    "    # parse with CLTK\n",
    "    s.passage.runCltkPipeline(index=False)\n",
    "    \n",
    "    if s.passage.cltk_doc is None:\n",
    "        failed.append(s)\n",
    "\n",
    "print(' done.')\n",
    "if len(failed) > 0:\n",
    "    print(f'CLTK pipeline failed for {len(failed)} speeches:')\n",
    "    for s in failed:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the results\n",
    "\n",
    "`Passage.cltk_doc` gives us acces to the `Doc` object created by CLTK's `NLP()`. It's a pretty complicated object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first speech\n",
    "s = speeches[0]\n",
    "\n",
    "# examine the results from CLTK\n",
    "print(s.passage.cltk_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to work with the NLP results is to iterate over `cltk_doc`: this will give you one word at a time (according to CLTK's partitioning of the text, anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first five words\n",
    "for word in s.passage.cltk_doc[:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's count the words spoken to each of Aphrodite's interlocutors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "for s in speeches:\n",
    "    for addressee in s.addr:\n",
    "        count[addressee.name] = count.get(addressee.name, 0) + len(s.passage.cltk_doc.words)\n",
    "\n",
    "for name in sorted(count):\n",
    "    print(name, count[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a simple graph with pyplot\n",
    "\n",
    "Seems good. Now let's visualize it with a simple bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for the graph\n",
    "names = sorted(count)\n",
    "y_pos = range(len(names))\n",
    "bars = [count[name] for name in names]\n",
    "\n",
    "# create a new figure\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# draw the bars\n",
    "ax.barh(y_pos, bars, align='center')\n",
    "\n",
    "# annotate the graph\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(names)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Number of Words')\n",
    "ax.set_ylabel('Addressee')\n",
    "ax.set_title('Length of Aphrodite\\'s speeches')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting additional details about words\n",
    "\n",
    "Each word object has many associated attributes, incuding the string as it appears in the original text, the lemma that CLTK has attributed it to, and some syntactical and morphological information.\n",
    "\n",
    "Here's a recipe for creating a big table of words, organizing some of those attribtues, using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict(\n",
    "    speech_id = s.id,\n",
    "    author = s.author.name,\n",
    "    work = s.work.title,\n",
    "    loci = s.l_range,\n",
    "    spkr = s.getSpkrString(),\n",
    "    addr = s.getAddrString(),\n",
    "    token = w.string,\n",
    "    lemma = w.lemma,\n",
    "    pos = w.upos, \n",
    ") for s in speeches for w in s.passage.cltk_doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
